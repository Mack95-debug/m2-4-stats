{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis points won\n",
    "\n",
    "In the `tennis.csv` files of games played by Federer.\n",
    "\n",
    "Does Federer score more total points than his opponent on average in a game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86.86952288218112 73.91723466407011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dft = pd.read_csv('/Users/kalebmckenzie/Documents/GitHub/m2-4-stats/data/tennis.csv')\n",
    "\n",
    "fed = dft['player1 total points won'].mean()\n",
    "op = dft['player2 total points won'].mean()\n",
    "print(fed, op)\n",
    "# On average Federer scores more points than his opposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. College correlations\n",
    "\n",
    "The `college.csv` filecontains a number of variables for 777 different universities and colleges in the US.\n",
    "\n",
    "### 2.1\n",
    "\n",
    "Use a scatterplot matrix to analyze the data and answer the following questions:\n",
    "\n",
    "1. Which columns are possibly from a normal distribution? Statistically test if this is the case (you'll find a function for it in `scipy.stats`). For each explain if it is or not normally distributed.\n",
    "\n",
    "2. Of the columns that aren't normally distributed, name which distribution could possibly fit them? (Use your research skills)\n",
    "\n",
    "3. Give 3 pairs of columns that are highly correlated? Give their correlation coefficients.\n",
    "\n",
    "4. Give 3 column pairs that are not correlated? Give their correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         Unnamed: 0 Private   Apps  Accept  Enroll  Top10perc  \\\n",
       "0      Abilene Christian University     Yes   1660    1232     721         23   \n",
       "1                Adelphi University     Yes   2186    1924     512         16   \n",
       "2                    Adrian College     Yes   1428    1097     336         22   \n",
       "3               Agnes Scott College     Yes    417     349     137         60   \n",
       "4         Alaska Pacific University     Yes    193     146      55         16   \n",
       "..                              ...     ...    ...     ...     ...        ...   \n",
       "772         Worcester State College      No   2197    1515     543          4   \n",
       "773               Xavier University     Yes   1959    1805     695         24   \n",
       "774  Xavier University of Louisiana     Yes   2097    1915     695         34   \n",
       "775                 Yale University     Yes  10705    2453    1317         95   \n",
       "776    York College of Pennsylvania     Yes   2989    1855     691         28   \n",
       "\n",
       "     Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  \\\n",
       "0           52         2885          537      7440        3300    450   \n",
       "1           29         2683         1227     12280        6450    750   \n",
       "2           50         1036           99     11250        3750    400   \n",
       "3           89          510           63     12960        5450    450   \n",
       "4           44          249          869      7560        4120    800   \n",
       "..         ...          ...          ...       ...         ...    ...   \n",
       "772         26         3089         2029      6797        3900    500   \n",
       "773         47         2849         1107     11520        4960    600   \n",
       "774         61         2793          166      6900        4200    617   \n",
       "775         99         5217           83     19840        6510    630   \n",
       "776         63         2988         1726      4990        3560    500   \n",
       "\n",
       "     Personal  PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0        2200   70        78       18.1           12    7041         60  \n",
       "1        1500   29        30       12.2           16   10527         56  \n",
       "2        1165   53        66       12.9           30    8735         54  \n",
       "3         875   92        97        7.7           37   19016         59  \n",
       "4        1500   76        72       11.9            2   10922         15  \n",
       "..        ...  ...       ...        ...          ...     ...        ...  \n",
       "772      1200   60        60       21.0           14    4469         40  \n",
       "773      1250   73        75       13.3           31    9189         83  \n",
       "774       781   67        75       14.4           20    8323         49  \n",
       "775      2115   96        96        5.8           49   40386         99  \n",
       "776      1250   75        75       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Private</th>\n      <th>Apps</th>\n      <th>Accept</th>\n      <th>Enroll</th>\n      <th>Top10perc</th>\n      <th>Top25perc</th>\n      <th>F.Undergrad</th>\n      <th>P.Undergrad</th>\n      <th>Outstate</th>\n      <th>Room.Board</th>\n      <th>Books</th>\n      <th>Personal</th>\n      <th>PhD</th>\n      <th>Terminal</th>\n      <th>S.F.Ratio</th>\n      <th>perc.alumni</th>\n      <th>Expend</th>\n      <th>Grad.Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abilene Christian University</td>\n      <td>Yes</td>\n      <td>1660</td>\n      <td>1232</td>\n      <td>721</td>\n      <td>23</td>\n      <td>52</td>\n      <td>2885</td>\n      <td>537</td>\n      <td>7440</td>\n      <td>3300</td>\n      <td>450</td>\n      <td>2200</td>\n      <td>70</td>\n      <td>78</td>\n      <td>18.1</td>\n      <td>12</td>\n      <td>7041</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adelphi University</td>\n      <td>Yes</td>\n      <td>2186</td>\n      <td>1924</td>\n      <td>512</td>\n      <td>16</td>\n      <td>29</td>\n      <td>2683</td>\n      <td>1227</td>\n      <td>12280</td>\n      <td>6450</td>\n      <td>750</td>\n      <td>1500</td>\n      <td>29</td>\n      <td>30</td>\n      <td>12.2</td>\n      <td>16</td>\n      <td>10527</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Adrian College</td>\n      <td>Yes</td>\n      <td>1428</td>\n      <td>1097</td>\n      <td>336</td>\n      <td>22</td>\n      <td>50</td>\n      <td>1036</td>\n      <td>99</td>\n      <td>11250</td>\n      <td>3750</td>\n      <td>400</td>\n      <td>1165</td>\n      <td>53</td>\n      <td>66</td>\n      <td>12.9</td>\n      <td>30</td>\n      <td>8735</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Agnes Scott College</td>\n      <td>Yes</td>\n      <td>417</td>\n      <td>349</td>\n      <td>137</td>\n      <td>60</td>\n      <td>89</td>\n      <td>510</td>\n      <td>63</td>\n      <td>12960</td>\n      <td>5450</td>\n      <td>450</td>\n      <td>875</td>\n      <td>92</td>\n      <td>97</td>\n      <td>7.7</td>\n      <td>37</td>\n      <td>19016</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alaska Pacific University</td>\n      <td>Yes</td>\n      <td>193</td>\n      <td>146</td>\n      <td>55</td>\n      <td>16</td>\n      <td>44</td>\n      <td>249</td>\n      <td>869</td>\n      <td>7560</td>\n      <td>4120</td>\n      <td>800</td>\n      <td>1500</td>\n      <td>76</td>\n      <td>72</td>\n      <td>11.9</td>\n      <td>2</td>\n      <td>10922</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>Worcester State College</td>\n      <td>No</td>\n      <td>2197</td>\n      <td>1515</td>\n      <td>543</td>\n      <td>4</td>\n      <td>26</td>\n      <td>3089</td>\n      <td>2029</td>\n      <td>6797</td>\n      <td>3900</td>\n      <td>500</td>\n      <td>1200</td>\n      <td>60</td>\n      <td>60</td>\n      <td>21.0</td>\n      <td>14</td>\n      <td>4469</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>Xavier University</td>\n      <td>Yes</td>\n      <td>1959</td>\n      <td>1805</td>\n      <td>695</td>\n      <td>24</td>\n      <td>47</td>\n      <td>2849</td>\n      <td>1107</td>\n      <td>11520</td>\n      <td>4960</td>\n      <td>600</td>\n      <td>1250</td>\n      <td>73</td>\n      <td>75</td>\n      <td>13.3</td>\n      <td>31</td>\n      <td>9189</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>Xavier University of Louisiana</td>\n      <td>Yes</td>\n      <td>2097</td>\n      <td>1915</td>\n      <td>695</td>\n      <td>34</td>\n      <td>61</td>\n      <td>2793</td>\n      <td>166</td>\n      <td>6900</td>\n      <td>4200</td>\n      <td>617</td>\n      <td>781</td>\n      <td>67</td>\n      <td>75</td>\n      <td>14.4</td>\n      <td>20</td>\n      <td>8323</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>Yale University</td>\n      <td>Yes</td>\n      <td>10705</td>\n      <td>2453</td>\n      <td>1317</td>\n      <td>95</td>\n      <td>99</td>\n      <td>5217</td>\n      <td>83</td>\n      <td>19840</td>\n      <td>6510</td>\n      <td>630</td>\n      <td>2115</td>\n      <td>96</td>\n      <td>96</td>\n      <td>5.8</td>\n      <td>49</td>\n      <td>40386</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>776</th>\n      <td>York College of Pennsylvania</td>\n      <td>Yes</td>\n      <td>2989</td>\n      <td>1855</td>\n      <td>691</td>\n      <td>28</td>\n      <td>63</td>\n      <td>2988</td>\n      <td>1726</td>\n      <td>4990</td>\n      <td>3560</td>\n      <td>500</td>\n      <td>1250</td>\n      <td>75</td>\n      <td>75</td>\n      <td>18.1</td>\n      <td>28</td>\n      <td>4509</td>\n      <td>99</td>\n    </tr>\n  </tbody>\n</table>\n<p>777 rows × 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dfc = pd.read_csv('/Users/kalebmckenzie/Documents/GitHub/m2-4-stats/data/college.csv')\n",
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Boxplot\n",
    "\n",
    "Make a boxplot of private vs outstate colleges. It should look like:\n",
    "\n",
    "![](boxplort.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auto data\n",
    "\n",
    "The `auto.csv` data file is malformed.\n",
    "\n",
    "Fix it (using only python) so that it can be read into pandas, and then give a scatterplot matrix of horsepower, weight, year and mpg.\n",
    "\n",
    "Did cars get more efficient over time? Make an argument on this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mpg\\tcylinders\\tdisplacement\\thorsepower weight\\tacceleration\\tyear\\torigin\\tname\n",
       "0                            -------------------------                               \n",
       "1    18.0   8   307.0      130.0      3504.      12...                               \n",
       "2    15.0   8   350.0      165.0      3693.      11...                               \n",
       "3    18.0   8   318.0      150.0      3436.      11...                               \n",
       "4    16.0   8   304.0      150.0      3433.      12...                               \n",
       "..                                                 ...                               \n",
       "393  27.0   4   140.0      86.00      2790.      15...                               \n",
       "394  44.0   4   97.00      52.00      2130.      24...                               \n",
       "395  32.0   4   135.0      84.00      2295.      11...                               \n",
       "396  28.0   4   120.0      79.00      2625.      18...                               \n",
       "397  31.0   4   119.0      82.00      2720.      19...                               \n",
       "\n",
       "[398 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg\\tcylinders\\tdisplacement\\thorsepower weight\\tacceleration\\tyear\\torigin\\tname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-------------------------</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.0   8   307.0      130.0      3504.      12...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15.0   8   350.0      165.0      3693.      11...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.0   8   318.0      150.0      3436.      11...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.0   8   304.0      150.0      3433.      12...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>27.0   4   140.0      86.00      2790.      15...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>44.0   4   97.00      52.00      2130.      24...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>32.0   4   135.0      84.00      2295.      11...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>28.0   4   120.0      79.00      2625.      18...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>31.0   4   119.0      82.00      2720.      19...</td>\n    </tr>\n  </tbody>\n</table>\n<p>398 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dfa = pd.read_csv('/Users/kalebmckenzie/Documents/GitHub/m2-4-stats/data/auto.csv')\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Auto Statistics\n",
    "\n",
    "What is the mean, median and standard deviation of each quantitative feature?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 data removal\n",
    "\n",
    "Remove the 10th through 85th observations. \n",
    "\n",
    "Does the mean statistically significantly change for each of the columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Boston housing dataset\n",
    "\n",
    "You can use `from sklearn.datasets import load_boston` to load the boston housing dataset.\n",
    "\n",
    "The `load_boston()['DESCR']` will describe columns for you.\n",
    "\n",
    "Are any of the columns associated with per capita crime rate? If so, show the numeric relationship and give a possible explanation for highly correlated/negatively correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/Users/kalebmckenzie/Applications/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 How many of the suburbs in this data set bound the Charles river?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 What is the median pupil-teacher ratio among the towns in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Which suburb of Boston has lowest median value of owneroccupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}